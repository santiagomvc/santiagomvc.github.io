[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog compiles technical notes from my experience working in Data Science and Machine Learning for the past few years."
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html",
    "href": "posts/entity_matching_intro/entity_matching_intro.html",
    "title": "Intro to Entity Matching",
    "section": "",
    "text": "Entity matching is the process of identifying entity descriptions from different sources that refer to the same real-world entity. This post is an applied introduction to some common approaches used for entity matching. Since even for small datasets the number of possible matches can become excessive, the process is usually split in two:\nThere are multiple tasks related to Entity Matching. Though they are different, some approaches may solve common issues.\nTL;DR: This paragraph in “Entity Matching using Large Language Models” is a good summary of the current status of Entity Matching in 2024:\n“We can summarize the high-level implications of our findings concerning the selection of matching techniques in the following rules of thumb: For use cases that do not involve many unseen entities and for which a decent amount of training data is available, PLM-based matchers are a suitable option which does not require much compute due to the smaller size of the models. For use cases that involve a relevant amount of unseen entities and for which it is costly to gather and maintain a decent size training set, LLM-based matchers should be preferred due to their high zero-shot performance and ability to generalize to unseen entities. If using the best performing hosted LLMs is not an option due to their high usage costs, fine-tuning a cheaper hosted model is an alternative that can deliver a similar F1 performance. If using using hosted models is no option due to privacy concerns, using an open-source LLM on local hardware can be an alternative providing a slightly lower F1 performance given that some task-specific training data or domain-specific matching rules are available.”\nRalph Peeters & Christian Bizer, “Entity Matching using Large Language Models”, 2024\nA more detailed explanation of Entity Matching can be found here"
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#when-to-use-ai-for-entity-matching",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#when-to-use-ai-for-entity-matching",
    "title": "Intro to Entity Matching",
    "section": "When to use AI for Entity Matching",
    "text": "When to use AI for Entity Matching\n\nIf a human can find a match with the presented data, is likely that a Modern AI approach can do it too\nIf a human is having issues finding a match, AI won’t be likely to help\nIf there’s not enough information presented to the model, AI won’t be able to find the match, even if a human has enough internal information to do it\n\nYou can run the following code on Google Colab clicking here."
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#setup",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#setup",
    "title": "Intro to Entity Matching",
    "section": "Setup",
    "text": "Setup\n\n# Downloading required libraries and packages\n!pip install transformers spacy numpy scipy py_entitymatching python-dotenv openai\n\n\n# Downloading spacy english package\n!python -m spacy download en_core_web_sm\n\n\n# Creating data for training/few-shot and evaluation\nsynt_data = [\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"John A. Smith\", \"entity_2\": \"John A. Smith\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Emily J. Clarke\", \"entity_2\": \"Emily T. Clarke\", \"match\": \"no\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Sarah M. Johnson\", \"entity_2\": \"Sarah Marie Johnson\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"James P. Miller\", \"entity_2\": \"James P. Miles\", \"match\": \"no\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Michael O'Leary\", \"entity_2\": \"Michael OLeary\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Nancy L. Wright\", \"entity_2\": \"Nancy W. Wright\", \"match\": \"no\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Catherine G. Davis\", \"entity_2\": \"Catherine Grace Davis\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Richard A. Lee\", \"entity_2\": \"Richard A. Lin\", \"match\": \"no\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Robert K. Brown\", \"entity_2\": \"Robert K. Brown Jr.\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Karen M. Harris\", \"entity_2\": \"Karen M. Harrison\", \"match\": \"no\"},\n]\n\nreal_data = [\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Spann-Wilder, Tiffany\", \"entity_2\": \"Tiffany Spann-Wilder\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Landon C. Dais\", \"entity_2\": \"Landon Dais\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Giglio JA\", \"entity_2\": \"Jodi Giglio\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"Brown, M\", \"entity_2\": \"Marla Gallo Brown\", \"match\": \"yes\"},\n    {\"chamber_1\": \"house\", \"chamber_2\": \"house\", \"entity_1\": \"J.T. 'Jabo' Waggoner  \", \"entity_2\": \"Jabo Waggoner\", \"match\": \"yes\"},\n]"
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#language-models",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#language-models",
    "title": "Intro to Entity Matching",
    "section": "Language Models",
    "text": "Language Models\nCurrently the best performing approach to Entity Disambiguation based on recent research. It usually consists of building a set of examples and assembling a prompt, in order to pass an unseen pair to the Language Model and get the relevant response. There’s some exploration into using LM to enhance existing Entity Linking models.\n\nAdvantages\n\nEasy to use: create examples, compose a prompt, call an API, and parse the results.\nPerformance above older models trained specifically for entity matching\nMay not require structuring the data as much as other options, just collapsing all the information in a single string.\nLM approach can be used to generate explanations and categories. Categories can be used to find common error cases (year, mixed words, etc.)\n\n\n\nDisadvantages\n\nPrompting is very sensible to changes\nMost powerful models are paid or hard to use\nNo candidate generation and blocking (can be done with other tools)\n\n\n\nBest LM Configuration - based on Entity Matching using LMs:\n\nModel: GPT4\nPrompt: Domain specific, complex prompt, free-form response (use regex to find ‘yes’)\nFew Shot: Yes, related examples\nFine-tuning helps, especially smaller models, without losing generalization\n\n\n# Loading libraries\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\n# Loading env and openai client\nload_dotenv(\".env\")   # Create an ENV file with OPENAI_API_KEY\nclient = OpenAI()\n\n# Building prompts for few shot learning\ntask_description = \"Do the two legislator names refer to the same real-world legislator?\"\ndemostration = \"legislator_1: '{entity_1}'\\nlegislator_2: '{entity_2}'\"\n\n\n# Creating examples for few shot learning\nfew_shot_messages = []\n# System Prompt\nfew_shot_messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n# Few shot Examples\nfor example in synt_data:\n    # Adds description\n    few_shot_messages.append({\"role\": \"user\", \"content\": task_description})\n    # Adds example\n    few_shot_messages.append({\"role\": \"user\", \"content\": demostration.format(entity_1=example[\"entity_1\"], entity_2=example[\"entity_2\"])})\n    # Adds correct answer\n    few_shot_messages.append({\"role\": \"assistant\", \"content\": example[\"match\"]})\n\n\n# Running the model for each real example\nfor sample in real_data:\n  messages = few_shot_messages.copy()\n  messages.append({\"role\": \"user\", \"content\": task_description})\n  messages.append({\"role\": \"user\", \"content\": demostration.format(entity_1=sample[\"entity_1\"], entity_2=sample[\"entity_2\"])})\n  response = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=messages,\n  )\n  print(\"Entity 1: \", sample[\"entity_1\"])\n  print(\"Entity 2: \", sample[\"entity_2\"])\n  print(\"Same Entity: \", response.choices[0].message.content)\n\nEntity 1:  Spann-Wilder, Tiffany\nEntity 2:  Tiffany Spann-Wilder\nSame Entity:  yes\nEntity 1:  Landon C. Dais\nEntity 2:  Landon Dais\nSame Entity:  yes\nEntity 1:  Giglio JA\nEntity 2:  Jodi Giglio\nSame Entity:  No, the two names 'Giglio JA' and 'Jodi Giglio' do not seem to refer to the same real-world legislator. 'Giglio JA' is likely an abbreviation or a format that includes initials, and 'Jodi Giglio' is a full name. Without additional context, they are likely different individuals.\nEntity 1:  Brown, M\nEntity 2:  Marla Gallo Brown\nSame Entity:  no\nEntity 1:  J.T. 'Jabo' Waggoner \nEntity 2:  Jabo Waggoner\nSame Entity:  yes"
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#bert-type-models-fine-tuned-for-entity-tasks",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#bert-type-models-fine-tuned-for-entity-tasks",
    "title": "Intro to Entity Matching",
    "section": "Bert-type Models Fine Tuned for Entity Tasks",
    "text": "Bert-type Models Fine Tuned for Entity Tasks\nOlder and smaller generation of Language Models, trained with general data but fine-tuned for entity tasks. Though some are trained for other tasks, most are trained for entity linking, which requires defining a Trie or Knowledge Base (usually WikiData). Changing the KB may require retraining the model\n\nAdvantages\n\nThe Blocking process is performed automatically for the existing Trie/Knowledge Base\nGood performance for data within training distribution\nMay not require additional training (depending on the model)\nYou can run it locally at no cost\n\n\n\nDisadvantages\n\nHard to train from scratch, which is recommended if data is out of distribution\nLimited Out of Distribution performance out of the box\nNeed to build a custom TRIE/KB or use generic KBs like WikiData\n\n\n\nRecommended Models\n\nFacebook GENRE\n\n\n\nFacebook Genre (Using Genre default Trie)\n\n# Loading libraries\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Loading model and tokenizers\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/genre-linking-aidayago2\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/genre-linking-aidayago2\").eval()\n\n# Processing text\nsentences = []\nfor example in real_data:\n    sentences.append(f\"[START_ENT] {example['entity_1']} [END_ENT]\")\n    sentences.append(f\"[START_ENT] {example['entity_2']} [END_ENT]\")\n\n# Running inference\nnum_beams = 3\noutputs = model.generate(\n    **tokenizer(\n        sentences, \n        return_tensors=\"pt\", \n        padding=True, \n        truncation=True,\n    ),\n    num_beams=num_beams,\n    num_return_sequences=num_beams,\n    # OPTIONAL: use constrained beam search\n    # prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),\n)\npreds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n# Printing results\ni = 0\nfor example in real_data:\n    print(\"Entity 1: \", example['entity_1'])\n    print(\"Entity 1 KB Candidates: \", preds[i:i+num_beams])\n    print(\"Entity 2: \", example['entity_2'])\n    print(\"Entity 2 KB Candidates: \", preds[i+num_beams:i+(num_beams*2)])\n    print(\"--\")\n    i += +(num_beams*2)\n\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nEntity 1:  Spann-Wilder, Tiffany\nEntity 1 KB Candidates:  ['Tiffany Spann-Wilder', 'Spann-Wilder, Tiffany', 'Tiffany Spann-Wilder, Tiffany']\nEntity 2:  Tiffany Spann-Wilder\nEntity 2 KB Candidates:  ['Tiffany Spann-Wilder', 'Tiffany Spann- Wilder', 'Tiffani Spann-Wilder']\n--\nEntity 1:  Landon C. Dais\nEntity 1 KB Candidates:  ['Landon C. Dais', 'Landon Dais', 'Landon C.Dais']\nEntity 2:  Landon Dais\nEntity 2 KB Candidates:  ['Landon Dais', 'LandonDais', 'Landon dais']\n--\nEntity 1:  Giglio JA\nEntity 1 KB Candidates:  ['Juan Antonio Giglio', 'Antonio Giglio', 'Jorge Antonio Giglio']\nEntity 2:  Jodi Giglio\nEntity 2 KB Candidates:  ['Jodi Giglio', 'Jodi Giglio (actress)', 'Jodi Giglio (singer)']\n--\nEntity 1:  Brown, M\nEntity 1 KB Candidates:  ['Mark Brown (American football)', 'Michael J. Brown', 'Michael Brown (American football)']\nEntity 2:  Marla Gallo Brown\nEntity 2 KB Candidates:  ['Marla Gallo Brown', 'Marla Gallo-Brown', 'Marla Gallo']\n--\nEntity 1:  J.T. 'Jabo' Waggoner \nEntity 1 KB Candidates:  ['J. T. Waggoner', \"J. T. 'Jabo' Waggoner\", 'Jabo Waggoner']\nEntity 2:  Jabo Waggoner\nEntity 2 KB Candidates:  ['Jabo Waggoner', 'Jabo Waggoner', 'Jambo Waggoner']\n--"
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#matching-systems-with-small-to-no-training",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#matching-systems-with-small-to-no-training",
    "title": "Intro to Entity Matching",
    "section": "Matching systems with Small to No Training",
    "text": "Matching systems with Small to No Training\nThis group encompasses traditional Entity Matching techniques that use similarity metrics or classic ML models to evaluate how likely are the entities to match. Some of these approaches will require labeled examples to train models, though training is mostly managed by the library. This approach is popular for tabular datasets with multiple attributes\n\nAdvantages\n\nSimpler matching algorithms (though libraries can be outdated)\nUsually includes candidate generation and blocking\nFast\n\n\n\nDisadvantages\n\nWorse performance in Entity Disambiguation compared to LM-based approaches\nRequires training data for some of the algorithms\nSome libraries are old and have not been updated for some time\n\n\n\nMatching Algorithms Examples\n\nJaccard similarity\nLevenstein distance\nCosine similarity of vectors\nRandom Forest Similarity Classifier\n\n\n\nRelated libraries:\n\nhttps://github.com/anhaidgroup/py_entitymatching\nhttps://docs.dedupe.io/en/latest/\nhttps://github.com/anhaidgroup/deepmatcher\nhttps://huggingface.co/shahrukhx01/paraphrase-mpnet-base-v2-fuzzy-matcher?text=fuzzformer\n\n\n\npy_entitymatching + Random Forest\n\n# Loading libraries\nimport pandas as pd\nimport py_entitymatching as em\n\n\n# Formatting data in required library configuration \n# Train set\ndf = pd.DataFrame(synt_data)\ndf = df.reset_index(names=\"id\").reset_index(names=\"ltable_id\").reset_index(names=\"rtable_id\")\ndf[\"match\"] = df[\"match\"].apply(lambda x: 1 if x==\"yes\" else 0)\nA = df[['ltable_id', 'chamber_1', 'entity_1']].rename({'ltable_id': 'id', 'chamber_1': 'chamber', 'entity_1': 'entity'}, axis=1)\nB = df[['rtable_id', 'chamber_2', 'entity_2']].rename({'rtable_id': 'id', 'chamber_2': 'chamber', 'entity_2': 'entity'}, axis=1)\nC = df[[\"id\", \"ltable_id\", \"rtable_id\", \"match\"]]\n\n# Test set\ntest_df = pd.DataFrame(real_data)\ntest_df = test_df.reset_index(names=\"id\").reset_index(names=\"ltable_id\").reset_index(names=\"rtable_id\")\ntest_df[\"match\"] = test_df[\"match\"].apply(lambda x: 1 if x==\"yes\" else 0)\nX = df[['ltable_id', 'chamber_1', 'entity_1']].rename({'ltable_id': 'id', 'chamber_1': 'chamber', 'entity_1': 'entity'}, axis=1)\nY = df[['rtable_id', 'chamber_2', 'entity_2']].rename({'rtable_id': 'id', 'chamber_2': 'chamber', 'entity_2': 'entity'}, axis=1)\nZ = df[[\"id\", \"ltable_id\", \"rtable_id\", \"match\"]]\n\n\n# Registering tables metadata in the library\nem.set_key(A, 'id')\nem.set_key(B, 'id')\nem.set_key(C, 'id')\nem.set_ltable(C, B)\nem.set_ltable(C, A)\n\nem.set_key(X, 'id')\nem.set_key(Y, 'id')\nem.set_key(Z, 'id')\nem.set_ltable(Z, X)\nem.set_ltable(Z, Y)\n\nTrue\n\n\n\n# Creating and blocking candidate matches (just for display)\nob = em.OverlapBlocker()\nC = ob.block_tables(A, B, 'entity', 'entity', \n                    l_output_attrs=['entity', 'chamber'], \n                    r_output_attrs=['entity', 'chamber'],\n                    overlap_size=1, show_progress=False)\n\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/py_entitymatching/blocker/overlap_blocker.py:258: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  l_df[l_dummy_overlap_attr] = l_df[l_overlap_attr]\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/py_entitymatching/blocker/overlap_blocker.py:259: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  r_df[r_dummy_overlap_attr] = r_df[r_overlap_attr]\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/py_entitymatching/blocker/overlap_blocker.py:615: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  table[overlap_attr] = values\n\n\n\n# Workaround - Saving labeled data so we are able to load it in the library with the right metadata\ndf = df.rename({'id':'_id', 'chamber_1': 'ltable_chamber', 'chamber_2': 'rtable_chamber', 'entity_1': 'ltable_entity',\n       'entity_2': 'rtable_entity', 'match': 'gold'}, axis=1)\ndf.to_csv(\"temp_df.csv\")\ntest_df = test_df.rename({'id':'_id', 'chamber_1': 'ltable_chamber', 'chamber_2': 'rtable_chamber', 'entity_1': 'ltable_entity',\n       'entity_2': 'rtable_entity', 'match': 'gold'}, axis=1)\ntest_df.to_csv(\"temp_test_df.csv\")\n\n\n# Load training data with metadata\nG = em.read_csv_metadata(\"temp_df.csv\", \n                         key='_id',\n                         ltable=A, rtable=B, \n                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n# Load test data with metadata\nZ = em.read_csv_metadata(\"temp_test_df.csv\", \n                         key='_id',\n                         ltable=X, rtable=Y, \n                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n\nMetadata file is not present in the given path; proceeding to read the csv file.\nMetadata file is not present in the given path; proceeding to read the csv file.\n\n\n\n# Selecting features for Entity Matching Model\nfeature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)\n\n\n# Building feature vectors for entity matching model\n# Select the attrs. to be included in the feature vector table\nattrs_from_table = ['ltable_entity', 'ltable_chamber',\n                    'rtable_entity', 'rtable_chamber',]\n# Convert the labeled data to feature vectors using the feature table\nH = em.extract_feature_vecs(G, \n                            feature_table=feature_table, \n                            attrs_before = attrs_from_table,\n                            attrs_after='gold',\n                            show_progress=False)\n\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n\n\n\n# Training entity matching model with training data\n# Instantiate the RF Matcher\nrf = em.RFMatcher()\n# Get the attributes to be projected while training\nattrs_to_be_excluded = []\nattrs_to_be_excluded.extend(['_id', 'ltable_id', 'rtable_id', 'gold'])\nattrs_to_be_excluded.extend(attrs_from_table)\n# Train using feature vectors from the labeled data.\nrf.fit(table=H, exclude_attrs=attrs_to_be_excluded, target_attr='gold')\n\n\n# Prepare test data for inference\n# Select the attrs. to be included in the feature vector table\nattrs_from_table = ['ltable_entity', 'ltable_chamber',\n                    'rtable_entity', 'rtable_chamber',]\n# Convert the cancidate set to feature vectors using the feature table\nL = em.extract_feature_vecs(Z, feature_table=feature_table,\n                             attrs_before= attrs_from_table,\n                             show_progress=False, n_jobs=-1)\n# Get the attributes to be excluded while predicting \nattrs_to_be_excluded = []\nattrs_to_be_excluded.extend(['_id', 'ltable_id', 'rtable_id'])\nattrs_to_be_excluded.extend(attrs_from_table)\n\n/Users/santiagovelez/anaconda3/envs/exp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n# Predict the matches on inference data\npredictions = rf.predict(table=L, exclude_attrs=attrs_to_be_excluded,                          \n              append=True, target_attr='predicted', inplace=False)\npredictions.head()\n\n\n\n\n\n\n\n\n_id\nltable_id\nrtable_id\nltable_entity\nltable_chamber\nrtable_entity\nrtable_chamber\nid_id_exm\nid_id_anm\nid_id_lev_dist\n...\nchamber_chamber_jac_qgm_3_qgm_3\nentity_entity_jac_qgm_3_qgm_3\nentity_entity_cos_dlm_dc0_dlm_dc0\nentity_entity_jac_dlm_dc0_dlm_dc0\nentity_entity_mel\nentity_entity_lev_dist\nentity_entity_lev_sim\nentity_entity_nmw\nentity_entity_sw\npredicted\n\n\n\n\n0\n0\n0\n0\nSpann-Wilder, Tiffany\nhouse\nTiffany Spann-Wilder\nhouse\n1\n0.0\n0.0\n...\n1.0\n1.000000\n1.000000\n1.000000\n1.000000\n0.0\n1.000000\n13.0\n13.0\n1\n\n\n1\n1\n1\n1\nLandon C. Dais\nhouse\nLandon Dais\nhouse\n1\n1.0\n0.0\n...\n1.0\n0.700000\n0.666667\n0.500000\n0.973333\n1.0\n0.933333\n14.0\n14.0\n0\n\n\n2\n2\n2\n2\nGiglio JA\nhouse\nJodi Giglio\nhouse\n1\n1.0\n0.0\n...\n1.0\n0.625000\n0.666667\n0.500000\n0.945395\n4.0\n0.789474\n12.0\n12.0\n1\n\n\n3\n3\n3\n3\nBrown, M\nhouse\nMarla Gallo Brown\nhouse\n1\n1.0\n0.0\n...\n1.0\n0.571429\n0.666667\n0.500000\n0.959048\n2.0\n0.866667\n12.0\n12.0\n0\n\n\n4\n4\n4\n4\nJ.T. 'Jabo' Waggoner\\t\nhouse\nJabo Waggoner\nhouse\n1\n1.0\n0.0\n...\n1.0\n0.736842\n0.500000\n0.333333\n0.986667\n1.0\n0.933333\n13.0\n13.0\n1\n\n\n\n\n5 rows × 26 columns"
  },
  {
    "objectID": "posts/entity_matching_intro/entity_matching_intro.html#sources",
    "href": "posts/entity_matching_intro/entity_matching_intro.html#sources",
    "title": "Intro to Entity Matching",
    "section": "Sources",
    "text": "Sources\n\nPython Libraries\n\nhttps://github.com/wbsg-uni-mannheim/MatchGPT/blob/main/LLMForEM\nhttps://huggingface.co/facebook/mgenre-wiki\nhttps://github.com/explosion/projects/tree/v3/tutorials/nel_emerson\nhttps://pypi.org/project/spacy-entity-linker/\nhttps://huggingface.co/shahrukhx01/paraphrase-mpnet-base-v2-fuzzy-matcher?text=fuzzformer\nhttps://github.com/megagonlabs/ditto\nhttps://dedupe.io\nhttps://github.com/anhaidgroup/deepmatcher\nhttps://nbviewer.org/github/anhaidgroup/py_entitymatching\nhttps://github.com/facebookresearch/GENRE\nhttps://github.com/Babelscape/multinerd?tab=readme-ov-file\nhttps://github.com/SapienzaNLP/extend?tab=readme-ov-file\nhttps://github.com/Lucaterre/spacyfishing\n\n\n\nPapers\n\nLLMAEL: Large Language Models are Good Context Augmenters for Entity Linking\nEntity Matching using Large Language Models\nEntGPT: Linking Generative Large Language Models with Knowledge Bases\nOn Leveraging Large Language Models for Enhancing Entity Resolution\nUsing ChatGPT for Entity Matching\n“Is This You?” Entity Matching in the Modern Data Stack with Large Language models\nDeepType: Multilingual Entity Linking by Neural Type System Evolution\nMultiNERD: A Multilingual, Multi-Genre and Fine-Grained Dataset for Named Entity Recognition (and Disambiguation)\nAUTOREGRESSIVE ENTITY RETRIEVAL\nDeep Entity Matching with Pre-Trained Language Models\nhttps://github.com/sebastianruder/NLP-progress/blob/master/english/entity_linking.md\nhttps://openai.com/index/discovering-types-for-entity-disambiguation/"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "",
    "text": "Anthropic/Menlo Builder Day was a one day event set on November 2 2024, focused mainly on sharing updates on Anthropic new developments, and encouraging Claude applications with a 4 hours hackathon. Here are my lightly edited notes on the event."
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#dario-fireside-chat",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#dario-fireside-chat",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Dario Fireside Chat",
    "text": "Dario Fireside Chat\n\nDriven by the question of intelligence\nScaling is extremely valuable\nText is easy to scale (lots of data, self supervised)\nSimple for RLFH too\nAlignment work is stronger in Anthropic (constitutional ai, interpretability)\n\nPersonal observation: Claude’s frontier models seem to have better meta understanding than other models. A few examples I have seen are better developer jokes, identifying the “needle in haystack” test, stop responses after a cycle of repeated inputs, etc.\n\nTalent density is the most important factor\nSpeed-size-quality trade off for models\nModels should be general purpose\nThe bigger model the more steerable\nModel personality is important for final user, more art than science\nModels should take actions (agents, ex: email legislators)\nAgents in the world have more range to do harm than regular chatbots\nClaude compute use still has some issues\nCode models will advance faster because they don’t need humans in the loop\n\nPersonal observation: Is there a path to improve system 2 reasoning there?\n\nWorkforce, legal, biomedicine software will grow faster\nStartups are exponential work, AI startups’ exponential grows quicker\nHard to know which advise to follow since current AI startups are different from previous types of startups\nModels will continue to be expensive (no room for more than 3 foundation models general companies), lots of companies for smaller and more specific models.\nMachines of Loving Grace:\n\nBiology improvements, healthcare, etc.\nDefending the country and its ideals\nWorry about the intentional bad use of the models\n\n500k context window for enterprise customers\nExtending the model context AND having the model perform well with the complete context is hard\nAsking models to write more succinctly usually reduces the quality of the response\n\nPersonal observation: I have seen this myself, models usually “think” by writing\n\nModels are able to identify and respond to what users want to hear, instead of what it may be a more accurate answer. LMSys may be biased due to “People Pleasing”\nCore models should be as good as possible, but there can be differenciation within that range\n\nPersonal observation: What about the ARC challenge?"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#anthropic-api-technical-deep-dive",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#anthropic-api-technical-deep-dive",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Anthropic API Technical Deep Dive",
    "text": "Anthropic API Technical Deep Dive\n\nUpgraded 3.5 Sonnet\n\nState of the art on coding\n\n3.5 Haiku coming soon\nComputer use\n\nUse apps, create docs, etc.\nUseful for developer unfriendly tasks\n\nPersonal observation: Web scrapers?\n\nPublic data and guide available, use through the api\nThere are prompting tips and techniques to constrain behavior and increase speed (like caching)\nIt’s a subset of tool use\nLimitations\n\nLatency\nAccuracy, specially on complex tasks\nScrolling is unreliable\nSpreadsheets\nAccount creations\nCaptchas (intentionally hard)\nVulnerabilities (prompt injection)\n\nPrompting tips\n\nLimit to simple well defined tasks\nConfirm output success\n\n\nPrompting recommendations\n\nDevelop test cases\nEngineer preliminary prompts and iterate\n\nWorkbench\n\nSupports variables\nImproves initial prompts\nSupport for building evaluation sets\nPersonal observation: How useful is it, are there any metrics?\n\nWhat’s next\n\nCustomize performance, improve latency, etc.\nInterpretability\nAlignment\nPre-training\n\nImprove vision compared to text capabilities\n\nEnhancing retrieval\nAgents and orchestration\n\nThey take Claude docs seriously"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#anthropicmenlo-anthology-fund",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#anthropicmenlo-anthology-fund",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Anthropic/Menlo Anthology Fund",
    "text": "Anthropic/Menlo Anthology Fund\n\n100M to invest in AI companies\nMention you were at Builder Day"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#hackathon-development-guidelines",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#hackathon-development-guidelines",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Hackathon Development Guidelines",
    "text": "Hackathon Development Guidelines\n\n4 hours of time\nIdeally should have started the project before\nIndividuals or group of 3\nMulti pass judge\nCriteria\n\nCreative\nImproves work productivity\nPotential for social good\n\n5 pm prejudging\n\n5 min per project\n\nPrizes\n\nFirst\n\n10k cash\n50k Anthropic credits\n50k AWS credits\n\nSecond\nThird"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#research-breakthroughs-in-interpretability",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#research-breakthroughs-in-interpretability",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Research Breakthroughs in Interpretability",
    "text": "Research Breakthroughs in Interpretability\nProbably the best talk of the day, but did not take notes because it was during development time.\n\nSuperposition hypothesis: Models represent many more sparse, interpretable variables than they have features. More information can be found here\nGolden Gate Claude is an application of these ideas\nThere are many hidden variables that the research team has not yet discovered"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#hackathon-project",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#hackathon-project",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Hackathon Project",
    "text": "Hackathon Project\nUsing previous work on public policy and bill summaries, I built a web app that receives a jurisdictions and a legislator, and returns the legislator informations, vote history with bill summaries, and a report on the vote history. Though the demo is down for now, here’s a gif for reference:"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#awards",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#awards",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Awards",
    "text": "Awards\n\nRobot arm piloting with Claude\nBuilding new captchas in the age of AI\n\nPersonal observation: Pretty smart and creative, my favorite of the 3\n\nImproving PRDs with custom personas powered by Claude"
  },
  {
    "objectID": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#final-thoughts",
    "href": "posts/anthropic_builder_day_02112024/anthropic_builder_day_02112024.html#final-thoughts",
    "title": "Notes on Anthropic & Menlo Builder Day",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nOverall it was a fun event with some really interesting talks. My main complain is that one day is not enough for multiple interesting talks and demo development (almost) from scratch, so either focusing on one or having multiple days would a be good idea."
  },
  {
    "objectID": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html",
    "href": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html",
    "title": "Is Artificial Intelligence a Risk for Public Policy?",
    "section": "",
    "text": "This is an extended version of the article published in Plural’s blog. You can find a shorter version here.\nCurrent Machine Learning models have the potential to automate and enhance activities in multiple fields, including Public Policy. Large Language Models can be used to summarize bills, extract entities, and even propose legislation. However, the same technology can be used to muffle the legislative process with biased responses, or help bad actors astroturf and hide harmful legislation. The complexity behind drafting and passing legislation makes the impact of AI even more difficult to understand."
  },
  {
    "objectID": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#policy-making-is-complex",
    "href": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#policy-making-is-complex",
    "title": "Is Artificial Intelligence a Risk for Public Policy?",
    "section": "Policy-Making is Complex",
    "text": "Policy-Making is Complex\nPolicy-making is a years-long process influenced by multiple actors, so the road from grassroots activism to executive signing can take significant time. The political nature of the work also makes it harder to get agreements even on fundamental levels. Bureaucracy combines with complexity to make the process inefficient and time-consuming, making most of the gains available to powerful organizations.\nTraditional data analysis and statistics have affected policy for a long time, from supporting data-based policies to predicting bill passing and election outcomes. However, the advent of powerful Machine Learning models and the advances in Natural Language Processing have allowed new and incredible use cases like identifying policy topics, extracting named entity jurisdictions, summarizing bills, and even chat-like question answering. This new technology has the ability to exert positive and negative influence on the policy-making process."
  },
  {
    "objectID": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#the-risks-of-using-ai-for-public-policy-work",
    "href": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#the-risks-of-using-ai-for-public-policy-work",
    "title": "Is Artificial Intelligence a Risk for Public Policy?",
    "section": "The Risks of Using AI for Public Policy Work",
    "text": "The Risks of Using AI for Public Policy Work\nMachine Learning and statistics can have a negative impact on Public Policy either by misunderstanding how models work or by using the models correctly for non-democratic objectives.\n\nBias in AI Data\nMachine Learning models learn from the data they are trained with, which means the input data has a defining effect on the model results. Since models are usually trained to minimize errors and maximize accuracy, it’s possible for models to learn artifacts that correlate with certain scenarios but are not causes of it. Models can also have great performance in average but regular performance for specific and important subgroups, which were likely less represented in the training data.\nResearch at MIT showed that around 2017 some commercial Gender Classification models displayed significant disparities in the classification of darker-skinned females and lighter-skinned males, with error rates of up to 34.7%. \nGiven the complexity, nuance, and variety in biases, there’s not a single and clear solution to the problems it raises. Google tried to improve its face recognition for its Pixel 4 phone, but it raised some criticism for the methods it used to gather the required data. This is a complex problem that must be treated accordingly.\n\n\nPersonal Information and Privacy Risks\nSince modern ML Models are being trained with terabytes and terabytes of data, it is almost impossible to manually verify that there’s no PII, private, or copyrighted information in the training sets. This means that, if the dataset was not cleaned correctly, your pictures, social security number, and medical information may be available without your permission. Even worse, some companies are consciously trying to collect this personal data with shady means.\nThere have been multiple cases in which police units have wrongfully jailed people due to errors in Face Recognition models, and more recently Samsung had to restrict access to ChatGPT due to leaked confidential information.\nAI providers are taking steps both to improve their data collection and the cases in which the technology can be used. OpenAI recently changed its policies to avoid collecting customers’ data for training by default, and multiple companies now restrict their Face Detection models to avoid military and police uses. At the end of the day though, companies will always want more data to train their models and more users to buy them, so this is a constant struggle. \n\n\nLack of Transparency in How Algorithms Work\nThe mathematical aspect of AI, ranging from linear algebra to information theory and density functions, is another source of opacity when integrating AI with public policy workers. This issue is amplified in Neural Networks, the building block to the best generative models, since there’s no simple interpretation of the parameters the model is learning, resulting in black box systems that experts find hard to trust. Adding to the transparency issues, the traditional openness around Machine Learning models and techniques is partially being replaced by shallow reports and closed releases, due in part to the strong competition in commercial AI.\nGPT4 Technical Report is an example of the current trend in AI development. While a few years back state-of-the-art models were shared publicly along with replication techniques, today most state-of-the-art models are kept private, and there’s not enough information shared to understand improvements and much less to try to replicate them. While some argue that this is part of Responsible AI principles to avoid misuse, others argue that it’s mostly about protecting private interests.\nGiven the tradition of open research in AI, there has been pushback around the new closed tendencies, like Facebook’s non-commercial release of their language models. And on the model opacity, there’s continued research around understanding how models work and impact different areas.\n\n\nModels are not perfect\nMost state-of-the-art AI models are probabilistic in nature, which means that they return the most likely answer, but there’s no strict enforcement on correctness, logic, or causality. Given the impressive results of Generative AI and the complexity behind it, it’s very easy for laypeople to misunderstand model results and use them in the wrong situations. To make matters worse, this complexity is often used by dishonest actors for their own personal gains.\nGiven the current capabilities of Language Models such as GPT4 and Bard, it’s easy to believe that they’re able to solve any task we ask. Memorizing large amounts of training data and being hyped by grifters does not help with the situation. However, multiple researchers have shown that the algorithms behind Language Models are unable to consistently solve multistep logical reasoning problems, for now. \nLanguage Models continue improving, and they may be able to evolve logical and analytical capabilities in the near future, whether by growing in size, improving world models, or other techniques we don’t even know yet. However, it’s important to understand and communicate the limitations of the current models we do have.\n\n\nNo Standards for AI Regulation\nThe growing complexity of Machine Learning and Generative algorithms, the quality jumps in model performance, the lack of technical knowledge in government, and the powerful actors involved are a brewing pot of issues for any attempt at regulation. \nAn example of the current regulatory status is the open discussion around AI Art. Tools like Stable Diffusion and Midjourney are incredible technologies that generate brand-new images in seconds, based on prompts made by users. These tools however are built using artists’ work and menace their monetizing abilities, since art with similar characteristics can be done in seconds. While artists have valid concerns, relying on copyright to address them may not be the best answer. \nIt seems like governments around the world are starting to understand Generative AI risks and opportunities, but there’s no clear path around regulation, and it’s important to note that some players may try to use it to stop competitors and maintain a competitive advantage. \n\n\nLack of Well-Defined Policy Goals\nThe Public Policy nature also contributes to the challenges around AI applications.The legal documents where public policy is supported are usually long, tangled, and full of legal terminology and technicalities. As any lawyer can confirm, words tend to have non-vernacular meanings and simple changes such as synonymous can significantly alter the legal meaning. Lastly, public policy is strongly connected to politics, where nuance and consensus are hard to find, and emotions are strong on either side of the aisle.   \nAn example of this is bills, which propose changes to current statutes. As such, what may seem like a simple change in a letter or a number can provoke meaningful transformations in public society, such as changing the minimum wage from $10 to $19. Arizona SCR 1023 is a good example of how small changes can significantly affect the meaning of the law.\nThere have been efforts to improve model performance in specific fields, as in Google’s latest release of med-palm 2, and there’s even open source work around specialized legal models. However, we need more targeted resources to work on the intersection of Public Policy and AI.\n\n\nUses cases that hurt democracy\nWhile most of the risks we described are provoked by misunderstandings or incompetence, there’s a very important issue left. Clever actors who understand AI and Public Policy can use modern technology in ways that undermine democracy. Those actions can be as simple as misleading descriptive statistics or as complex as deep-fake political images and simulated grassroots movements.\nResearchers at Stanford University displayed how GPT3 can be used to draft persuasive political messages. Similar models have been used to generate fake reviews on Amazon and to cheat in high school homework, and they could be used just as easily to fake public interest in relevant policy topics or to draft bills with undemocratic objectives. \nThere’s a growing understanding in policy circles that this technology can affect public policy, and senators have publically interacted with some of the tools. Even AI companies are limiting the ways the models can be used in policy settings, but it’s not enough. This technology exists and is being used right now, and the Plural, Public, and Private sectors need to agree on the ways AI should not be used to affect public policy."
  },
  {
    "objectID": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#the-biggest-challenge",
    "href": "posts/ai_risks_for_public_policy/ai_risks_for_public_policy.html#the-biggest-challenge",
    "title": "Is Artificial Intelligence a Risk for Public Policy?",
    "section": "The Biggest Challenge",
    "text": "The Biggest Challenge\nPublic Policy impacts everyone, and there’s a real risk in how slowly government and public institutions will adapt and how fast will actors move and break things. We can see how unregulated new technology can impact the lives of thousands of people, and how sooner action could have prevented some of the harm.\nRight now we need strong pressure from the public and grassroots organizations to accelerate government action and guarantee that corporate interests are aligned with the public benefit, like Google employees did with Project Maven, while maintaining incentives to continue research that improves the lives of the community.\nWhile this article focuses on risks around ML and Generative AI, it’s also clear that the technology can be used to make the public policy process more accessible and democratic, as we argue in Summarizing Bills With Generative AI."
  },
  {
    "objectID": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html",
    "href": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html",
    "title": "Summarizing Bills With Generative AI",
    "section": "",
    "text": "This is an old version of an article published in Plural’s blog. You can find the new version here.\nSo far in 2023, thousands of bills have been introduced in jurisdictions across the country. The sooner people understand them, the sooner they can start advocating for what they care about. Since bills can be long and complex, it’s often helpful to have a summary of the changes the bill is proposing.\nLet’s take SB 396:\n“TO CREATE THE SOCIAL MEDIA SAFETY ACT; TO REQUIRE AGE VERIFICATION FOR USE OF SOCIAL MEDIA; AND TO CLARIFY LIABILITY FOR FAILURE TO PERFORM AGE VERIFICATION FOR USE OF SOCIAL MEDIA AND ILLEGAL RETENTION OF DATA.”.\nThis bill, from Arkansas’s 2023 Session,  regulates minors’ use of social media, like verifying users’ age and requiring minors to have parental consent. The bill is pages long with technical jargon and multiple textual changes. In this case, as for most Arkansas bills, the release does not include a legislature provided summary.\nGiven the advancements of Artificial Intelligence in language tasks, we believe Language Models can help us understand bills. Here’s an AI summary for SB 396:\n“In SB 396, the bill proposes the creation of the Social Media Safety Act, which requires social media companies to verify the age of account holders, obtain parental consent for minors, and use reasonable age verification methods, which may include obtaining digitized identification or using other commercially reasonable age verification methods. The bill specifies that social media companies that knowingly violate the proposed act will be liable for damages resulting from a minor accessing a social media platform. The bill also outlines liability for commercial entities and third-party vendors related to the retention of identifying information after access to a social media platform has been granted.”"
  },
  {
    "objectID": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#summarizing-bill-texts",
    "href": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#summarizing-bill-texts",
    "title": "Summarizing Bills With Generative AI",
    "section": "Summarizing Bill Texts",
    "text": "Summarizing Bill Texts\nLanguage Models (LM) are specific generative models trained with big amounts of unstructured text data, with the goal of predicting the next word or the words adjacent inside the text corpus. With enough training data, number of parameters and computing power, these models can perform language tasks at human level and even maintain logical conversations. Language models are at the base of technologies such as ChatGPT, Bard, and others.\nGiven the current capabilities of LM and generative AI, we decided to try using it to summarize bills. There’s ample evidence of using LLM to summarize new articles, emails, contracts, and even short stories. Longer texts such as books still present a challenge. Given the success in other fields, we decided to analyze bill texts using common summarization techniques. \nBut it’s not a trivial task! Our first round of testing revealed some barriers and rough edges to this approach. Here are a few examples of our first round of AI generated summaries, with corresponding Policy Expert Evaluations:\n\n\n\nBill Name \nAI Model-Generated Summary\nPolicy Expert Evaluation\n\n\nSF 13: Juneteenth (June 19) state holiday recognition - Minnesota 2023-2024 REGULAR SESSION\nThis bill recognizes Juneteenth, June 19th, as a state holiday and amends Minnesota Statutes 2022, sections 10.55 and 645.44, subdivision 5. It also requires the governor to issue a proclamation honoring the observance and recognizing the contributions African-Americans have made to Minnesota’s communities, culture, and economy. Additionally, public schools may offer instruction and programs on the occasion. The bill also states that when Juneteenth falls on a Sunday or Saturday, the following or preceding day shall be a holiday.\nCapturing the main intent of the bill, establishing Juneteenth as a state holiday, is quite impressive given that this would be a difficult bill for a layperson to understand. However, the summary indicates that the bill creates new requirements for the governor to issue a proclamation and encourages public school instruction on Juneteenth. In this, the summary is incorrect as that text already existed in statute and is not newly added by this legislation. \n\n\nSF 23: Conversion therapy prohibition establishment - Minnesota 2023-2024 REGULAR SESSION\nThis bill prohibits conversion therapy with children or vulnerable adults, prohibits medical assistance coverage for conversion therapy, and prohibits the misrepresentation of conversion therapy services or products. It defines conversion therapy as any practice by a mental health practitioner or professional that seeks to change an individual’s sexual orientation or gender identity, and prohibits the use of any fraud, false pretense, false promise, false guarantee, misrepresentation, false or misleading statements, or deceptive practice when advertising or offering conversion therapy services.\nThis summary does an excellent job of concisely summarizing the bills main actions and the details that really matter, like how these terms are defined.  \n\n\nSF 15: Full Social Security benefit subtraction and public pension benefit subtraction establishment - Minnesota 2023-2024 REGULAR SESSION\nThis bill amends Minnesota Statutes 2022 to establish a public pension benefit subtraction for individual income taxation. It sets out the maximum subtraction and threshold amounts for married taxpayers filing a joint return, single or head-of-household taxpayers, and married taxpayers filing separate returns. It also defines provisional income, public pension exclusion, qualified benefits, and the maximum state exclusion. It also amends Minnesota Statutes 2022, section 290.091, subdivision 2, to define alternative minimum taxable income, investment interest, net minimum tax, regular tax, and tentative minimum tax. This section is effective for taxable years beginning after December 31, 2022.\nThe summary doesn’t include the bill’s proposed removal of the cap on social security income that a taxpayer can subtract, which is a huge part of the impact of the bill. The latter half of the summary, starting with “it also defines provisional”, is also inaccurate as the bill itself makes no changes to law here. The model is interpreting existing statute text as if it is what the bill is proposing.\n\n\n\nAs you can see, while the model is able to summarize some bills successfully, there are other cases where the model confuses statute and bill text, giving an incorrect summary of the proposed bill."
  },
  {
    "objectID": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#summarizing-bill-changes",
    "href": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#summarizing-bill-changes",
    "title": "Summarizing Bills With Generative AI",
    "section": "Summarizing Bill Changes",
    "text": "Summarizing Bill Changes\nUsing AI and LM to summarize bills may be more complex than it seems. Since bills are mainly proposed changes to current statutes, if we pass the proposed text to a summarization model, it is often not able to differentiate between current and proposed law. However, if we pass only the changes in text, the model won’t have the necessary context to understand what the bill is proposing to change —  for instance, modifying the minimum wage from $12 to $15 may be a single character change.\nAfter additional research and help from our policy experts, we were able to find a combination of models and prompts that correctly identify most of the changes, with a better understanding of the current statutes and proposed law. Although it’s not perfect, the performance is significantly better.\n\n\n\nBill Name\nModel Summary\nPolicy Expert Evaluation\n\n\nSF 13: Juneteenth (June 19) state holiday recognition - Minnesota 2023-2024 REGULAR SESSION\nSF 13 proposes to amend Minnesota Statutes 2022, sections 10.55 and 645.44, subdivision 5, to recognize Juneteenth, June 19, as a state holiday in Minnesota. It specifies that Juneteenth is to be observed annually on the third Saturday in June and includes Juneteenth as a holiday in the definition of “Holiday” along with other nationally recognized holidays. The bill also mandates the governor to issue a proclamation honoring the observance and recognizing the contributions made by African-Americans to Minnesota’s communities, culture, and economy.\nThis is a really hard one to get, but it does a pretty good job. Ideally, it would indicate that the first section of the bill changes Juneteenth from being recognized on the third Saturday, to being recognized on June 19th.\n\n\nSF 23: Conversion therapy prohibition establishment - Minnesota 2023-2024 REGULAR SESSION\nThe bill proposed in SF 23 aims to prohibit conversion therapy with minors and vulnerable adults, prohibit medical assistance coverage for conversion therapy, and prohibit the misrepresentation of conversion therapy services or products. It also proposes amending Minnesota Statutes to add a new law to protect individuals from conversion therapy and to add definitions for conversion therapy and related terms, as well as outlining penalties for those who engage in or advertise conversion therapy.\nVery good again. 100% accurate.\n\n\nSF 15: Full Social Security benefit subtraction and public pension benefit subtraction establishment - Minnesota 2023-2024 REGULAR SESSION\nSF 15 is proposing an amendment to Minnesota Statutes related to taxation and individual income. The bill proposes to establish a public pension benefit subtraction and make amendments to sections 290.0132 and 290.091 of the Minnesota Statutes.The bill would add a new subdivision 31 to section 290.0132 to establish a public pension income subtraction. The subtraction would be determined by the sum of the federal and state exclusions, with the maximum state exclusion being $5,450 for a joint return, half that amount for a married taxpayer filing a separate return, and $4,260 for all other taxpayers.The bill would also amend subdivision 26 of section 290.0132 related to Social Security benefits. It would allow a portion of taxable Social Security benefits received by a taxpayer in a taxable year as a subtraction. The maximum subtraction would be determined based on the taxpayer’s filing status and provisional income.Finally, the bill would amend subdivision 2 of section 290.091 related to the definitions of terms used in the tax imposed by that section.\nThis summarization is accurate and valuable. There are some things that are slightly incorrect — for example, in paragraph 3, it says “it would allow a portion of taxable social….”, when in fact the bill allows all social security taxes to be subtracted, not a portion."
  },
  {
    "objectID": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#next-steps",
    "href": "posts/summarizing_bills_with_genai/summarizing_bills_with_genai.html#next-steps",
    "title": "Summarizing Bills With Generative AI",
    "section": "Next steps",
    "text": "Next steps\nDespite improved performance, there are still hurdles to overcome. LMs can hallucinate, confidently share wrong answers, and even give biased responses. LMs also have a hard time analyzing very long texts, so large omnibus bills may be out of the question for now. Finally, there’s a lot of room for improvement in the model and prompting area besides this experiment.\nWhile limitations exist, it’s likely that LMs and Generative AI can support and improve policy analysis, as it has been shown in other text based fields. While this remains a hard problem, we’re committed to keep exploring the edges of the intersection between AI and Public Policy."
  },
  {
    "objectID": "posts/intro_to_search_algorithms/intro_to_search_algorithms.html",
    "href": "posts/intro_to_search_algorithms/intro_to_search_algorithms.html",
    "title": "Applied Intro to Search Algorithms",
    "section": "",
    "text": "Information Retrieval and Reranking is a wide field with significant nuance and incredible importance to multiple businesses. This post is an applied introduction to building a simple search application, displaying three common approaches to search, one to reranking, and some basic evaluation metrics. This is not intended as a deep dive into each algorithm, but as a high-level display of the basic components required to build a search solution. For more information please review the references at the end of the post.\nTL;DR: BM25 is the default for a reason: simple, fast, and accurate. You should start there and use it as the benchmark for other approaches. If you have time and require increased accuracy, Colbert is worth exploring, but focus first on gathering data and building evaluation metrics.\nYou can run the following code on Google Colab clicking here."
  },
  {
    "objectID": "posts/intro_to_search_algorithms/intro_to_search_algorithms.html#references",
    "href": "posts/intro_to_search_algorithms/intro_to_search_algorithms.html#references",
    "title": "Applied Intro to Search Algorithms",
    "section": "References",
    "text": "References\n\nhttps://web.stanford.edu/class/cs276/handouts/lecture12-bm25etc.pdf\nhttps://zilliz.com/learn/mastering-bm25-a-deep-dive-into-the-algorithm-and-application-in-milvus\nhttps://huggingface.co/tasks/sentence-similarity\nhttps://github.com/stanford-futuredata/ColBERT\nhttps://arxiv.org/abs/2004.12832\nhttps://til.simonwillison.net/llms/colbert-ragatouille\nhttps://amenra.github.io/ranx/\nhttps://trec.nist.gov/pubs/trec2/papers/txt/23.txt"
  },
  {
    "objectID": "posts/installing_torch_cpu_with_poetry/installing_torch_cpu_with_poetry.html",
    "href": "posts/installing_torch_cpu_with_poetry/installing_torch_cpu_with_poetry.html",
    "title": "Installing Torch CPU with Poetry",
    "section": "",
    "text": "Having a working poetry environment that installs only cpu supported versions of torch is a good way to reduce the size of your docker container and speed up deployments. The following is a rough solution that seems to work (locally on Mac and Docker container) and could be used while torch and poetry solve their compatibility issues.\nInside your regular pyproject.toml file, include in [tool.poetry.dependencies] the following torch definition:\ntorch = [\n     {url=\"https://download.pytorch.org/whl/cpu/torch-2.0.0%2Bcpu-cp39-cp39-linux_x86_64.whl\", markers=\"platform_system == \\\"Linux\\\"\"},\n     {url=\"https://download.pytorch.org/whl/cpu/torch-2.0.0-cp39-none-macosx_10_9_x86_64.whl\", markers=\"platform_system == \\\"Darwin\\\" and platform_machine == \\\"x86_64\\\"\"},\n     {url=\"https://download.pytorch.org/whl/cpu/torch-2.0.0-cp39-none-macosx_11_0_arm64.whl\", markers=\"platform_system == \\\"Darwin\\\" and platform_machine == \\\"arm64\\\"\"}\n ]\nWhy is such an ugly solution required? Here are some apparent torch-poetry compatibility issues:\n\npoetry install torch==2.0.1 omits required gpu drivers for linux, which makes the container small but unusable Pytorch 2.0.1 pypi wheel does not install dependent cuda libraries pytorch/pytorch#100974.\npip and poetry install by default torch-cpu in mac and torch-gpu in linux . When specifying https://download.pytorch.org/whl/cpu as package source to install torch-cpu-linux, Poetry is unable to find a torch-cpu-mac version to use (Does not find a *+cpu version for mac). poetry add with –index-url option python-poetry/poetry#7685, Instructions for installing PyTorch python-poetry/poetry#6409 (comment).\npoetry may have issues dynamically selecting python wheels based on platforms (doesn’t happen if you use the wheel link) Install wheel based on platform python-poetry/poetry#1616.\n\nHere are some (so far) unsuccessful attempts to find a more elegant solution:\nAttempt 1:\n[tool.poetry.dependencies]\ntorch = { version = \"2.0.0\", source=\"torch\"}\n\n[[tool.poetry.source]]\nname = \"torch\"\nurl = \"https://download.pytorch.org/whl/cpu\"\npriority = \"explicit\" or \"suplemental\"\nAttempt 2:\n[tool.poetry.dependencies]\ntorch = [\n     {version = \"^2.0.0\", platform = \"darwin\"},\n     {version = \"^2.0.0\", platform = \"linux\", source = \"torch\"},\n     {version = \"^2.0.0\", platform = \"win32\", source = \"torch\"},\n]\n\n[[tool.poetry.source]]\nname = \"torch\"\nurl = \"https://download.pytorch.org/whl/cpu\"\npriority = \"explicit\"\nAttempt 3:\n[[tool.poetry.source]]\nname = \"torch_cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\npriority = \"supplemental\"\n\n[[tool.poetry.source]]\nname = \"PyPI\"\npriority = \"primary\"\n\n[tool.poetry.dependencies]\ntorch = { version = \"&gt;=2.0.0, !=2.0.1\", source=\"torch_cpu\" }\nAttempt 4:\n[[tool.poetry.source]]\nname = \"PyPI\"\npriority = \"primary\"\n\n[[tool.poetry.source]]\nname = \"linux_cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\npriority = \"supplemental\"\n\n[tool.poetry.group.linux_cpu]\noptional = true\n\n[tool.poetry.group.linux_cpu.dependencies]\ntorch = { version = \"&gt;=2.0.0, !=2.0.1\", source=\"linux_cpu\"}\n\n[tool.poetry.group.darwin_cpu]\noptional = true\n\n[tool.poetry.group.darwin_cpu.dependencies]\ntorch = { version = \"&gt;=2.0.0, !=2.0.1\"}\nIn most attempts, the error was around the inability to find a torch-cpu-mac version to install when the https://download.pytorch.org/whl/cpu repo was included."
  },
  {
    "objectID": "posts/ml_practice_building_features/ml_practice_building_features.html",
    "href": "posts/ml_practice_building_features/ml_practice_building_features.html",
    "title": "ML Practice: Building Features",
    "section": "",
    "text": "This post shares some of the learnings from building ML practices at tech companies. Each organization is different, so take everything with a pinch of salt.\nBusiness problems should be solved in the simplest way possible, but not simpler. The process of analyzing and modeling data is frequently complex since it requires interdisciplinary work, historical data (usually in large amounts), and specialized algorithmic knowledge to tackle open-ended problems that may not have a solution. As a result, model training should be used in cases where traditional business rules and domain expertise come short. Simple heuristics can go a long way, especially in issues never addressed before. Though there are common business problems and existing solutions, most ML features will go through an experimental phase due to quirks in the data and specifics in the problem."
  },
  {
    "objectID": "posts/ml_practice_building_features/ml_practice_building_features.html#business-features-and-ml",
    "href": "posts/ml_practice_building_features/ml_practice_building_features.html#business-features-and-ml",
    "title": "ML Practice: Building Features",
    "section": "Business features and ML",
    "text": "Business features and ML\nThere’s no single way to separate ML (DS, AI, etc.) from other engineering work. Nevertheless, here are some ideas that can be used to identify problems best suited for ML:\n\nUnstructured data problems with existing ML solutions (ex: Face recognition, Voice to Text translation, Short Text Summarization).\nUnstructured data problems commonly solved by training ML models (Text classification, custom image classification).\nProblems commonly solved with statistical models (Uplift modeling, multi-armed bandits, survival analysis).\nStructured classification and regression problems commonly solved with ML (Churn detection, sales forecasts).\nIndustry-specific problems with imperfect solutions (Tumor detection, bill summarization, weather forecasting).\n\nEven if a problem matches one of the categories above, it may not be fixable at the moment. Some possible reasons are:\n\nThe problem’s nature makes it hard to solve through existing methods (ex: predicting stocks, and weather).\nBusiness rules or domain expertise works sufficiently well.\nThere’s no clear reason why a data-based approach may improve current performance.\nNot enough quality data available.\nVery low to no margin of error (autonomous weapons).\nDeep domain expertise is required and not available (Public Policy, Medical Imaging).\nSpecialized technical knowledge is required and not available (Reinforcement Learning, Distributed Learning).\nThe infrastructure required is not available or affordable (Large GPU training clusters, Large inference clusters).\n\nBefore starting ML development to build a business feature, here are some useful questions to ask:\n\nWhy should this problem be solved with a data-based approach?\nWhat data could be used to solve this issue?\nDo we have the data to try to solve this issue?\nCan the data be trusted?\nWhen and how is the data updated?\nWhat is the process to get the required data?\nWhat family of models is best suited to solve this issue?\nHow much data do I have for modeling/analysis?\nWhat metrics should I use?\nHow is the data distribution changing over time?\nHow does the existing research approach the problem?"
  },
  {
    "objectID": "posts/ml_practice_building_features/ml_practice_building_features.html#ml-lifecycle-frameworks",
    "href": "posts/ml_practice_building_features/ml_practice_building_features.html#ml-lifecycle-frameworks",
    "title": "ML Practice: Building Features",
    "section": "ML Lifecycle Frameworks",
    "text": "ML Lifecycle Frameworks\nThe increased uncertainty in ML projects makes quick iteration and user validation even more relevant. There are multiple frameworks proposed to manage the Data Science and Machine Learning lifecycle. Though we won’t explain them in detail, some of them are:\n\nKnowledge Discovery in Databases (KDD)\n\n\n\nKDD\n\n\nhttps://www.sciencedirect.com/topics/computer-science/knowledge-discovery-in-database\n\n\nCross Industry Standard Process for Data Mining (CRISP-DM)\n\n\n\nCRISP DM\n\n\nhttps://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining\n\n\nTeam Data Science Process (TDSP)\n\n\n\nTDSP\n\n\nhttps://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview\n\n\nCommon Patterns in ML Lifecycle Frameworks\n\nBusiness understanding is usually the starting point.\nData analysis and transformations are very important.\nThere’s always continual iteration between modeling and deployment.\nMetrics and evaluations enable improvements in the cycle."
  },
  {
    "objectID": "posts/ml_practice_building_features/ml_practice_building_features.html#ml-feature-development",
    "href": "posts/ml_practice_building_features/ml_practice_building_features.html#ml-feature-development",
    "title": "ML Practice: Building Features",
    "section": "ML Feature Development",
    "text": "ML Feature Development\nDeveloping ML features can be divided into continual iterations of four steps, three required and one optional depending on the specific project:\n\nExperimentation\nEvaluation\nDeployment\nIntegration\n\nSome features will require additional work from external teams (DE, Web developers) to be used. Though it’s not the ML team’s direct responsibility, if it fails the feature won’t reach the final user. That’s why Integration is included as part of the cycle.\nIterating through this process as soon as possible allows us to gather user feedback and reduce uncertainty. However, minimal requirements are needed to develop ML safely and effectively.\n\nRequirements before the initial iteration\n\nBusiness problem description\nSample of input data\nSample of labeled data (if required)\nExpected deployment pattern\nExpected integration plan\nMeasurable success criteria\nImplemented baseline metrics (if possible)\nDefined usage metrics (with direct or indirect feedback)\nDefined model metrics\n\nFirst deployment threshold\nFinal deployment threshold (proposed)\n\n\n\n\nRequirements to close the initial iteration\n\nDeployment threshold met\nReplicable experimental code\nBasic deployment code\nBasic integration code (if required)\nModular deployment/integration to allow quick model changes\nUsage metrics collection implemented\n\n\n\nRequirements to close the final iteration\n\nProduction-ready training and inference code with tests\nFinal deployment metrics met\nComplete input data available\nSuccess metrics collection implemented (if required)\nData drift metrics implemented\n\nThough this may be the final part of an active ML development, as long as the model is in production some evaluation metrics should be required.\n\n\nCommon issues to avoid\n\nNo integration resources are available for the project\nVery short projects with a single iteration"
  },
  {
    "objectID": "posts/ml_practice_building_features/ml_practice_building_features.html#references",
    "href": "posts/ml_practice_building_features/ml_practice_building_features.html#references",
    "title": "ML Practice: Building Features",
    "section": "References",
    "text": "References\n\nhttps://www.ibm.com/docs/en/spss-modeler/saas?topic=dm-crisp-help-overview\nhttps://link.springer.com/chapter/10.1007/978-1-4471-0351-6_12\nhttps://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview\nhttps://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SMVC Notes",
    "section": "",
    "text": "Notes on Anthropic & Menlo Builder Day\n\n\n\n\n\n\nai\n\n\nlm\n\n\nanthropic\n\n\nclaude\n\n\nmenlo\n\n\nevents\n\n\nhackathon\n\n\n\nClaude keeps getting better\n\n\n\n\n\nNov 3, 2024\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nML Practice: Building Features\n\n\n\n\n\n\nml_practice\n\n\nml\n\n\nai\n\n\nfeatures\n\n\nbusiness\n\n\n\nHear what business wants and build what users need.\n\n\n\n\n\nSep 28, 2024\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Entity Matching\n\n\n\n\n\n\nentity-matching\n\n\nnlp\n\n\ncode\n\n\npython\n\n\nlm\n\n\ngpt4\n\n\ngenre\n\n\nrf\n\n\n\nMatching entities in a sea of data\n\n\n\n\n\nJul 21, 2024\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nApplied Intro to Search Algorithms\n\n\n\n\n\n\nsearch\n\n\nreranking\n\n\ncode\n\n\npython\n\n\nbm25\n\n\ncolbert\n\n\nsentence-transformers\n\n\n\nRetrieval and Reranking in Python\n\n\n\n\n\nJul 14, 2024\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nInstalling Torch CPU with Poetry\n\n\n\n\n\n\ncode\n\n\npython\n\n\ntorch\n\n\npoetry\n\n\n\nIt sucks, at least for now\n\n\n\n\n\nSep 11, 2023\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nIs Artificial Intelligence a Risk for Public Policy?\n\n\n\n\n\n\nai\n\n\nlm\n\n\npublic policy\n\n\n\nSomeone needs to talk about it\n\n\n\n\n\nMay 22, 2023\n\n\nSantiago Velez\n\n\n\n\n\n\n\n\n\n\n\n\nSummarizing Bills With Generative AI\n\n\n\n\n\n\nai\n\n\nlm\n\n\npublic policy\n\n\n\nUsing Language Models to summarize changes to existing legislation\n\n\n\n\n\nApr 20, 2023\n\n\nSantiago Velez\n\n\n\n\n\n\nNo matching items"
  }
]